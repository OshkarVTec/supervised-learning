{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a208b138",
   "metadata": {},
   "source": [
    "# Actividad 2.2: Aprendizaje supervisado\n",
    "Oskar Villa\n",
    "\n",
    "Cruz Pérez\n",
    "\n",
    "Rogelio Hernández"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea09e0fa",
   "metadata": {},
   "source": [
    "## Investigación documental: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cc4619",
   "metadata": {},
   "source": [
    "### Descripción General\n",
    "\n",
    "El clasificador **Random Forest** es un algoritmo de aprendizaje supervisado que pertenece a la categoría de métodos de *ensamble*. Su funcionamiento se basa en la construcción de múltiples árboles de decisión durante el entrenamiento, cuya salida se combina para producir una predicción final más precisa y robusta. Para tareas de clasificación, el resultado se determina por votación mayoritaria entre los árboles individuales.\n",
    "\n",
    "### Funcionamiento\n",
    "\n",
    "Random Forest emplea la técnica de *bootstrap aggregating* (también conocida como *bagging*), que consiste en:\n",
    "\n",
    "1. Generar subconjuntos aleatorios del conjunto de datos original, con reemplazo.\n",
    "2. Entrenar un árbol de decisión independiente en cada subconjunto.\n",
    "3. En cada división del árbol, se selecciona aleatoriamente un subconjunto de características para elegir la mejor partición.\n",
    "4. La predicción final se realiza mediante votación entre los árboles (en clasificación) o promedio (en regresión).\n",
    "\n",
    "Este enfoque permite reducir la varianza del modelo y mejora su capacidad de generalización.\n",
    "\n",
    "### Tipos de Datos que Maneja\n",
    "\n",
    "El clasificador Random Forest puede manejar:\n",
    "\n",
    "- Datos estructurados en formato tabular.\n",
    "- Variables tanto numéricas como categóricas.\n",
    "- Conjuntos de datos con valores faltantes o ruidosos.\n",
    "- Variables no escaladas (no requiere normalización o estandarización).\n",
    "\n",
    "### Principales Parámetros\n",
    "\n",
    "| Parámetro            | Descripción                                                                 |\n",
    "|----------------------|-----------------------------------------------------------------------------|\n",
    "| `n_estimators`       | Número de árboles que compondrán el bosque.                                |\n",
    "| `max_depth`          | Profundidad máxima permitida de los árboles.                               |\n",
    "| `min_samples_split`  | Número mínimo de muestras requeridas para dividir un nodo.                 |\n",
    "| `max_features`       | Número máximo de características consideradas para dividir en cada nodo.   |\n",
    "| `bootstrap`          | Indica si se utiliza muestreo con reemplazo al generar los subconjuntos.  |\n",
    "| `criterion`          | Función empleada para medir la calidad de una división (`gini`, `entropy`).|\n",
    "\n",
    "\n",
    "### Referencias\n",
    "\n",
    "- Breiman, L. (2001). *Random Forests*. *Machine Learning*, 45(1), 5–32.  \n",
    "  [https://link.springer.com/article/10.1023/A:1010933404324](https://link.springer.com/article/10.1023/A:1010933404324)\n",
    "- Scikit-learn documentation. *Random Forest Classifier*.  \n",
    "  [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- Géron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2898c",
   "metadata": {},
   "source": [
    "## Datos y objetivo de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeec633",
   "metadata": {},
   "source": [
    "> Los datos se componen de dos archivos con distintos tipos de vinos (red y white). Estos datos se procesarán de la siguiente manera:  \n",
    "> • Seleccionar un tipo de vino  \n",
    "> • Seleccionar solo dos clases a analizar, y determinar cuál será la clase objetivo (por ejemplo: Trabajaremos con la clase 5 y 7, pero nuestra clase objetivo es la 5. **IMPORTANTE**: Recuerda que, aunque los tipos de vino se determinan mediante un entero, son atributos ordinales).  \n",
    "> • Determinar qué métrica de evaluación utilizarán para estos experimentos  \n",
    "> • De acuerdo con la selección de los puntos anteriores, generar un conjunto de entrenamiento y uno de evaluación con el 70% y 30% de las instancias respectivamente. Cuidar que se conserve la proporción de las dos clases en cada conjunto.  \n",
    "> • Determinar si necesitan o no transformación de datos, en caso de necesitarla, generar los archivos correspondientes, en caso de que no, justificar su elección.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25556618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Wine Quality Counts:\n",
      "quality\n",
      "6    2198\n",
      "5    1457\n",
      "7     880\n",
      "8     175\n",
      "4     163\n",
      "3      20\n",
      "9       5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Red Wine Quality Counts:\n",
      "quality\n",
      "5    681\n",
      "6    638\n",
      "7    199\n",
      "4     53\n",
      "8     18\n",
      "3     10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the white wine and red wine datasets\n",
    "white_wine_data = pd.read_csv('data/winequality-white.csv')\n",
    "red_wine_data = pd.read_csv('data/winequality-red.csv')\n",
    "\n",
    "# Count the number of appearances of each class in the 'quality' column for each dataset\n",
    "white_wine_quality_counts = white_wine_data['quality'].value_counts()\n",
    "red_wine_quality_counts = red_wine_data['quality'].value_counts()\n",
    "\n",
    "print(\"White Wine Quality Counts:\")\n",
    "print(white_wine_quality_counts)\n",
    "\n",
    "print(\"\\nRed Wine Quality Counts:\")\n",
    "print(red_wine_quality_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd91bd",
   "metadata": {},
   "source": [
    "### Objetivo de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c4c0e1",
   "metadata": {},
   "source": [
    "Para mantener un balance de clases, se seleccionaron los siguientes datos:\n",
    "* Se utilizará vino blanco (white)\n",
    "* Se usarán las clases 4 y 8. La clase objetivo es 4.\n",
    "* Las métricas de evaluación serán accuracy y F1 score, ya que F1 es una métrica que combina Recall y Precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d9425",
   "metadata": {},
   "source": [
    "### Entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d2bb6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      "quality\n",
      "8    122\n",
      "4    114\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set label distribution:\n",
      "quality\n",
      "8    53\n",
      "4    49\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter the white wine dataset to include only quality 4 and 8\n",
    "filtered_white_wine = white_wine_data[white_wine_data['quality'].isin([4, 8])]\n",
    "\n",
    "# Separate features and target\n",
    "X = filtered_white_wine.drop(columns=['quality'])\n",
    "y = filtered_white_wine['quality']\n",
    "\n",
    "# Perform train-test split with stratification to maintain label balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Verify the balance of labels in both splits\n",
    "print(\"Training set label distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nTest set label distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490c399",
   "metadata": {},
   "source": [
    "### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cadd8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.918220</td>\n",
       "      <td>0.326059</td>\n",
       "      <td>0.317288</td>\n",
       "      <td>5.039831</td>\n",
       "      <td>0.045237</td>\n",
       "      <td>30.065678</td>\n",
       "      <td>126.542373</td>\n",
       "      <td>0.993330</td>\n",
       "      <td>3.210763</td>\n",
       "      <td>0.488051</td>\n",
       "      <td>10.877966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.004059</td>\n",
       "      <td>0.148333</td>\n",
       "      <td>0.128789</td>\n",
       "      <td>4.278606</td>\n",
       "      <td>0.023650</td>\n",
       "      <td>20.253577</td>\n",
       "      <td>45.314085</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.159046</td>\n",
       "      <td>0.129205</td>\n",
       "      <td>1.343963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.987130</td>\n",
       "      <td>2.830000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>1.587500</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.991038</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>9.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.900000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>0.993020</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.400000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.050250</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.995138</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.200000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>138.500000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>1.000600</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count     236.000000        236.000000   236.000000      236.000000   \n",
       "mean        6.918220          0.326059     0.317288        5.039831   \n",
       "std         1.004059          0.148333     0.128789        4.278606   \n",
       "min         4.400000          0.120000     0.000000        0.700000   \n",
       "25%         6.400000          0.227500     0.260000        1.587500   \n",
       "50%         6.900000          0.290000     0.310000        3.600000   \n",
       "75%         7.400000          0.380000     0.370000        7.250000   \n",
       "max        10.200000          1.005000     0.880000       15.400000   \n",
       "\n",
       "        chlorides  free sulfur dioxide  total sulfur dioxide     density  \\\n",
       "count  236.000000           236.000000            236.000000  236.000000   \n",
       "mean     0.045237            30.065678            126.542373    0.993330   \n",
       "std      0.023650            20.253577             45.314085    0.002831   \n",
       "min      0.013000             3.000000             10.000000    0.987130   \n",
       "25%      0.034000            15.000000             96.000000    0.991038   \n",
       "50%      0.041000            29.000000            122.000000    0.993020   \n",
       "75%      0.050250            39.000000            155.000000    0.995138   \n",
       "max      0.290000           138.500000            272.000000    1.000600   \n",
       "\n",
       "               pH   sulphates     alcohol  \n",
       "count  236.000000  236.000000  236.000000  \n",
       "mean     3.210763    0.488051   10.877966  \n",
       "std      0.159046    0.129205    1.343963  \n",
       "min      2.830000    0.250000    8.400000  \n",
       "25%      3.090000    0.387500    9.800000  \n",
       "50%      3.200000    0.470000   10.900000  \n",
       "75%      3.320000    0.570000   12.000000  \n",
       "max      3.720000    0.950000   14.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ddea38",
   "metadata": {},
   "source": [
    "No hay datos nulos y parecen no contener outliers significativos a simple vista. Solo se realizará normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4db2b",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the training and test data\n",
    "X_train_normalized = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_normalized = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Display the normalized data\n",
    "print(\"Normalized Training Data:\")\n",
    "print(X_train_normalized.head())\n",
    "\n",
    "print(\"\\nNormalized Test Data:\")\n",
    "print(X_test_normalized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d4b69",
   "metadata": {},
   "source": [
    "## Implementación de algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e24fe",
   "metadata": {},
   "source": [
    "> Implementa los siguientes algoritmos de clasificación (puede ser código propio o con librerías especializadas):\n",
    "> 1. Knn  \n",
    "> 2. Árbol de decisión  \n",
    "> 3. Algoritmo investigado en el punto 1 (puede ser con la ayuda de una librería o con código propio)  \n",
    "\n",
    "> Recuerda agregar el código para evaluar los modelos con accuracy y la métrica seleccionada en los puntos anteriores, puede ser `classification_report` de Scikit-learn o programar tus propias métricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2afec9",
   "metadata": {},
   "source": [
    "## Experimentación y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001dfbae",
   "metadata": {},
   "source": [
    "> Para cada algoritmo, generen al menos 8 experimentos variando los parámetros.  \n",
    "> * Para cada modelo, clasifica el conjunto de entrenamiento y evaluación, recuerda obtener las métricas para cada uno.  \n",
    "> * Muestren la exactitud en gráficas, de tal modo que se puede apreciar si existe overfitting y/o underfitting. Describe las gráficas obtenidas por modelo.  \n",
    "> * Muestra los resultados de la métrica seleccionada por medio de tablas y/o gráficas. Redacta los hallazgos que consideren importantes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee726d",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32911fe6",
   "metadata": {},
   "source": [
    "> Redacta las conclusiones del experimento, toma en cuenta los siguientes puntos:  \n",
    "> • ¿Qué algoritmo tuvo un mejor desempeño? ¿Con qué parámetros se logró esto?  \n",
    "> • ¿Hay diferencia significativa entre los diferentes algoritmos?  \n",
    "> • ¿Los resultados obtenidos permiten usar estos modelos en sector vitivinícola? ¿Por qué?  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
